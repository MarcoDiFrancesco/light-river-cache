{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "task = \"reg\"\n",
    "task = \"clf\"\n",
    "\n",
    "if task == \"clf\":\n",
    "    task_name = \"Classification\"\n",
    "elif \"reg\":\n",
    "    task_name = \"Regression\"\n",
    "\n",
    "fpath_notopt_times = f'res_{task}_notopt_times.csv'\n",
    "fpath_opt_times = f'res_{task}_opt_times.csv'\n",
    "\n",
    "fpath_notopt_depth = f'res_{task}_notopt_depth.csv'\n",
    "\n",
    "fpath_notopt_sorted_count = f'res_{task}_notopt_sorted_count.csv'\n",
    "fpath_opt_sorted_count = f'res_{task}_opt_sorted_count.csv'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python vs Rust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axissize = 18\n",
    "legendsize = 16\n",
    "ticksize=16\n",
    "titlesize=20\n",
    "dpi=150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def python_vs_rust(python_times, rust_times, task, task_name):\n",
    "    df_python = pd.DataFrame(python_times, columns=['Execution Time (sec)'])\n",
    "    df_rust = pd.DataFrame(rust_times, columns=['Execution Time (sec)'])\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(10, 6), dpi=dpi)\n",
    "    plt.bar('Python', df_python['Execution Time (sec)'].mean(), yerr=df_python['Execution Time (sec)'].std(), color='orange', alpha=0.7, label='Execution Time (sec)')\n",
    "    plt.bar('Rust', df_rust['Execution Time (sec)'].mean(), yerr=df_rust['Execution Time (sec)'].std(), color='red', alpha=0.7)\n",
    "    \n",
    "    plt.xlabel('Programming Languages', fontsize=axissize)\n",
    "    plt.ylabel('Execution Time (sec)', fontsize=axissize)\n",
    "    plt.title(f'Execution Time of Python vs Rust for {task_name}', fontsize=titlesize)\n",
    "    \n",
    "    plt.xticks(fontsize=ticksize)\n",
    "    plt.yticks(fontsize=ticksize)\n",
    "    \n",
    "    # plt.legend(fontsize=legendsize)\n",
    "    plt.grid(True)\n",
    "    plt.savefig(f'plots/python-vs-rust-{task}.png', dpi=dpi)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# Provided times for Python and Rust\n",
    "python_times = [\n",
    "    11.77, 10.62, 10.00, 9.46, 10.90, 10.50, 8.48, 11.26, 9.98, 10.40,\n",
    "    9.18, 9.98, 9.16, 10.43, 9.31, 8.96, 12.19, 10.97, 9.15, 9.91,\n",
    "    9.77, 12.49, 11.29, 10.32, 14.11, 10.17, 9.60, 10.85, 11.47, 10.57,\n",
    "    10.34, 11.78, 9.52, 10.21, 10.53, 10.83, 11.63, 11.94, 10.05, 9.11\n",
    "]\n",
    "\n",
    "rust_times = [\n",
    "    2.845, 2.919, 2.835, 2.818, 3.067, 2.988, 3.084, 2.790, 2.818, 2.791,\n",
    "    2.807, 2.803, 2.797, 2.804, 2.780, 2.786, 2.807, 2.792, 2.791, 2.827,\n",
    "    2.971, 3.015, 2.960, 2.958, 2.835, 2.868, 2.816, 2.944, 2.845, 2.993,\n",
    "    2.840, 2.881, 2.833, 2.853, 2.935, 2.908, 2.920, 2.861, 2.900, 2.824\n",
    "]\n",
    "\n",
    "python_vs_rust(python_times, rust_times, \"clf\", \"Classification\")\n",
    "print(f\"Python: {np.array(python_times).mean():.2f}±{np.array(python_times).var():.2f}\")\n",
    "print(f\"Rust: {np.array(rust_times).mean():.2f}±{np.array(rust_times).var():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression\n",
    "# Provided new times for Python and Rust\n",
    "python_times = [\n",
    "    13.02, 13.19, 12.64, 13.14, 12.93, 13.27, 13.46, 13.45, 14.24, 13.26,\n",
    "    13.58, 12.96, 13.44, 13.44, 13.38, 12.60, 13.33, 12.52, 13.01, 13.54,\n",
    "    13.09, 13.57, 13.33, 13.43, 13.82, 13.83, 12.94, 12.50, 13.21, 14.28,\n",
    "    13.35, 12.88, 13.52, 13.57, 14.24, 13.78, 13.65, 13.59, 13.38, 13.43\n",
    "]\n",
    "\n",
    "rust_times = [\n",
    "    0.456, 0.458, 0.462, 0.468, 0.465, 0.472, 0.463, 0.475, 0.475, 0.471,\n",
    "    0.480, 0.447, 0.467, 0.448, 0.471, 0.472, 0.507, 0.454, 0.460, 0.476,\n",
    "    0.476, 0.473, 0.485, 0.481, 0.463, 0.478, 0.529, 0.446, 0.459, 0.503,\n",
    "    0.473, 0.447, 0.450, 0.523, 0.483, 0.462, 0.470, 0.449, 0.483, 0.477\n",
    "]\n",
    "\n",
    "python_vs_rust(python_times, rust_times, \"reg\", \"Regression\")\n",
    "print(f\"Python: {np.array(python_times).mean():.2f}±{np.array(python_times).var():.2f}\")\n",
    "print(f\"Rust: {np.array(rust_times).mean():.2f}±{np.array(rust_times).var():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execution time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 50000\n",
    "\n",
    "axissize = 20\n",
    "legendsize = 16\n",
    "ticksize=16\n",
    "titlesize=24\n",
    "dpi=150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_no_caching = pd.read_csv(fpath_notopt_times)\n",
    "data_caching = pd.read_csv(fpath_opt_times)\n",
    "\n",
    "# Display the first few rows of each dataset to understand their structure\n",
    "data_no_caching_head = data_no_caching.head()\n",
    "data_caching_head = data_caching.head()\n",
    "\n",
    "data_no_caching.columns = ['Inference Time', 'Train Time', 'Total Time']\n",
    "data_caching.columns = ['Inference Time', 'Train Time', 'Total Time']\n",
    "\n",
    "# Add the optimization labels\n",
    "data_no_caching['Optimization'] = 'Without Optimization'\n",
    "data_caching['Optimization'] = 'With Optimization'\n",
    "\n",
    "# Add block numbers to both datasets\n",
    "data_no_caching['Block'] = (data_no_caching.index // block_size) + 1\n",
    "data_caching['Block'] = (data_caching.index // block_size) + 1\n",
    "\n",
    "combined_data = pd.concat([data_no_caching, data_caching])\n",
    "\n",
    "# Nano seconds to Micro seconds\n",
    "combined_data['Inference Time'] = combined_data['Inference Time'] / 1000\n",
    "combined_data['Train Time'] = combined_data['Train Time'] / 1000\n",
    "combined_data['Total Time'] = combined_data['Total Time'] / 1000\n",
    "\n",
    "combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new figure\n",
    "plt.figure(figsize=(14, 8), dpi=dpi)\n",
    "\n",
    "# Create a boxplot using seaborn to handle the coloring more effectively\n",
    "sns.boxplot(x='Block', y='Total Time', hue='Optimization', data=combined_data, \n",
    "            palette={'With Optimization': 'lightblue', 'Without Optimization': 'lightgreen'}, showfliers=False)\n",
    "\n",
    "plt.title(f'Total execution time per iteration on {task_name} task', fontsize=titlesize)\n",
    "plt.xlabel('Record Segments (Thousands)', fontsize=axissize)\n",
    "plt.ylabel('Time (µs)', fontsize=axissize)\n",
    "plt.xticks(ticks=range(len(combined_data['Block'].unique())), \n",
    "           labels=[f\"{int(i*block_size/1000)}-{int((i+1)*block_size/1000)}\" for i in range(len(combined_data['Block'].unique()))],\n",
    "           rotation=45, fontsize=ticksize)\n",
    "\n",
    "# Set yticks font size\n",
    "plt.yticks(fontsize=ticksize)\n",
    "\n",
    "plt.legend(title='Optimization', title_fontsize=legendsize, fontsize=legendsize)\n",
    "\n",
    "plt.grid(True)\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig(f'plots/time-per-iter-tot-{task}.png', dpi=dpi)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melt the data for plotting with specific labels\n",
    "melted_data = pd.melt(combined_data, id_vars=['Block', 'Optimization'], value_vars=['Inference Time', 'Train Time'], \n",
    "                      var_name='Time Type', value_name='Time')\n",
    "\n",
    "melted_data['Category'] = melted_data['Optimization'] + ' - ' + melted_data['Time Type']\n",
    "\n",
    "# Filter for Train Time only\n",
    "train_time_data = melted_data[melted_data['Time Type'] == 'Train Time']\n",
    "\n",
    "# Create the box plot with the specified categories\n",
    "plt.figure(figsize=(16, 10), dpi=dpi)\n",
    "\n",
    "sns.boxplot(x='Block', y='Time', hue='Category', data=train_time_data, showfliers=False, \n",
    "            palette={'With Optimization - Train Time': 'lightcoral', \n",
    "                     'Without Optimization - Train Time': 'lightyellow'})\n",
    "\n",
    "plt.title(f'Train execution time per iteration on {task_name} task', fontsize=titlesize)\n",
    "plt.xlabel('Record Segments (Thousands)', fontsize=axissize)\n",
    "plt.ylabel('Time (µs)', fontsize=axissize)\n",
    "plt.xticks(ticks=range(len(combined_data['Block'].unique())), \n",
    "           labels=[f\"{int(i*block_size/1000)}-{int((i+1)*block_size/1000)}\" for i in range(len(combined_data['Block'].unique()))],\n",
    "           rotation=45, fontsize=ticksize)\n",
    "\n",
    "plt.legend(title='Category', title_fontsize=legendsize, fontsize=legendsize)\n",
    "plt.grid(True)\n",
    "\n",
    "plt.savefig(f'plots/time-per-iter-train-{task}.png', dpi=dpi)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for Inference Time only\n",
    "inference_time_data = melted_data[melted_data['Time Type'] == 'Inference Time']\n",
    "\n",
    "# Create the box plot with the specified categories\n",
    "plt.figure(figsize=(16, 10), dpi=dpi)\n",
    "\n",
    "sns.boxplot(x='Block', y='Time', hue='Category', data=inference_time_data, showfliers=False, \n",
    "            palette={'With Optimization - Inference Time': 'lightseagreen', \n",
    "                     'Without Optimization - Inference Time': 'paleturquoise'})\n",
    "\n",
    "plt.title(f'Inference execution time per iteration on {task_name} task', fontsize=titlesize)\n",
    "plt.xlabel('Record Segments (Thousands)', fontsize=axissize)\n",
    "plt.ylabel('Time (µs)', fontsize=axissize)\n",
    "plt.xticks(ticks=range(len(combined_data['Block'].unique())), \n",
    "           labels=[f\"{int(i*block_size/1000)}-{int((i+1)*block_size/1000)}\" for i in range(len(combined_data['Block'].unique()))],\n",
    "           rotation=45, fontsize=ticksize)\n",
    "\n",
    "plt.legend(title='Category', title_fontsize=legendsize, fontsize=legendsize)\n",
    "plt.grid(True)\n",
    "\n",
    "# plt.ylim(0, 140000)\n",
    "# plt.xlim(0, 12.5)\n",
    "\n",
    "plt.savefig(f'plots/time-per-iter-inf-{task}.png', dpi=dpi)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melt the data for plotting with specific labels\n",
    "melted_data = pd.melt(combined_data, id_vars=['Block', 'Optimization'], value_vars=['Inference Time', 'Train Time'], \n",
    "                      var_name='Time Type', value_name='Time')\n",
    "\n",
    "# Combine Optimization and Time Type for clearer labels in the plot\n",
    "melted_data['Category'] = melted_data['Optimization'] + ' - ' + melted_data['Time Type']\n",
    "\n",
    "# Create the box plot with the specified categories\n",
    "plt.figure(figsize=(16, 10), dpi=dpi)\n",
    "\n",
    "sns.boxplot(x='Block', y='Time', hue='Category', data=melted_data, showfliers=False, \n",
    "            palette={'With Optimization - Inference Time': 'lightseagreen', \n",
    "                     'Without Optimization - Inference Time': 'paleturquoise', \n",
    "                     'With Optimization - Train Time': 'lightcoral', \n",
    "                     'Without Optimization - Train Time': 'lightyellow'\n",
    "                     })\n",
    "\n",
    "plt.title(f'Train and inference execution time per iteration on {task_name} task', fontsize=titlesize)\n",
    "plt.xlabel('Record Segments (Thousands)', fontsize=axissize)\n",
    "plt.ylabel('Time (µs)', fontsize=axissize)\n",
    "plt.xticks(ticks=range(len(combined_data['Block'].unique())), \n",
    "           labels=[f\"{int(i*block_size/1000)}-{int((i+1)*block_size/1000)}\" for i in range(len(combined_data['Block'].unique()))],\n",
    "           rotation=45, fontsize=ticksize)\n",
    "\n",
    "plt.legend(title='Category', title_fontsize=legendsize, fontsize=legendsize)\n",
    "plt.grid(True)\n",
    "\n",
    "# plt.ylim(0, 70000)\n",
    "\n",
    "# plt.savefig()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Number of Nodes (Image not saved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axissize = 20\n",
    "legendsize = 14\n",
    "ticksize=16\n",
    "titlesize=22\n",
    "dpi=150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(fpath_notopt_depth, header=None)\n",
    "\n",
    "# Assuming the file has 5 columns, use only the first one\n",
    "nodes_count = data.iloc[:, 0]\n",
    "\n",
    "# Create a DataFrame for plotting\n",
    "df = pd.DataFrame({'Number of Records': range(1, len(nodes_count) + 1), 'Number of Nodes': nodes_count})\n",
    "\n",
    "# Multiply the number of records by 1000\n",
    "df['Number of Records'] = df['Number of Records'] * 1000\n",
    "\n",
    "# Plot the data again with the updated number of records\n",
    "plt.figure(figsize=(12, 6), dpi=dpi)\n",
    "plt.plot(df['Number of Nodes'], df['Number of Records'], color='purple')\n",
    "plt.title('Number of Nodes Over Records', fontsize=titlesize)\n",
    "plt.xlabel('Number of Nodes', fontsize=axissize)\n",
    "plt.ylabel('Number of Records', fontsize=axissize)\n",
    "plt.xticks(fontsize=ticksize)\n",
    "plt.yticks(fontsize=ticksize)\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the CSV file\n",
    "data = pd.read_csv(fpath_notopt_depth, header=None)\n",
    "\n",
    "# Split the single column into four separate columns\n",
    "# data = data[0].str.split(',', expand=True)\n",
    "\n",
    "# Assign column names\n",
    "data.columns = ['Number of Nodes', 'Optimal Depth', 'Average Depth', 'Average Weighted Depth', 'Max Depth']\n",
    "\n",
    "# Convert columns to appropriate types\n",
    "data['Number of Nodes'] = data['Number of Nodes'].astype(float)\n",
    "data['Optimal Depth'] = data['Optimal Depth'].astype(float)\n",
    "data['Average Depth'] = data['Average Depth'].astype(float)\n",
    "data['Average Weighted Depth'] = data['Average Weighted Depth'].astype(float)\n",
    "data['Max Depth'] = data['Max Depth'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the data with secondary y-axis for Average Weighted Depth\n",
    "fig, ax1 = plt.subplots(figsize=(10, 6), dpi=dpi)\n",
    "\n",
    "# Plot Optimal Depth, Average Depth, and Max Depth on the primary y-axis\n",
    "ax1.plot(data['Number of Nodes'], data['Optimal Depth'], label='Optimal Depth (log2(#nodes))')\n",
    "ax1.plot(data['Number of Nodes'], data['Average Depth'], label='Average Depth')\n",
    "ax1.plot(data['Number of Nodes'], data['Max Depth'], label='Max Depth', color='orange')\n",
    "\n",
    "# Set labels and title for the primary y-axis\n",
    "ax1.set_xlabel('Number of Nodes', fontsize=axissize)\n",
    "ax1.set_ylabel('Depth', fontsize=axissize)\n",
    "ax1.set_title('Depth Metrics Over Number of Nodes', fontsize=titlesize)\n",
    "ax1.legend(loc='lower right', fontsize=legendsize)\n",
    "ax1.grid(True)\n",
    "\n",
    "# Set tick sizes\n",
    "ax1.tick_params(axis='both', which='major', labelsize=ticksize)\n",
    "\n",
    "plt.savefig(f'plots/depths-{task}.png', dpi=dpi)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the data with secondary y-axis for Average Weighted Depth\n",
    "fig, ax1 = plt.subplots(figsize=(10, 6), dpi=dpi)\n",
    "\n",
    "# Plot Optimal Depth, Average Depth, and Max Depth on the primary y-axis\n",
    "# ax1.plot(data['Number of Nodes'], data['Optimal Depth'], label='Optimal Depth (log2(#nodes))')\n",
    "# ax1.plot(data['Number of Nodes'], data['Average Depth'], label='Average Depth')\n",
    "ax1.plot(data['Number of Nodes'], data['Max Depth'], label='Max Depth', color='orange')\n",
    "\n",
    "# Set labels and title for the primary y-axis\n",
    "ax1.set_xlabel('Number of Nodes', fontsize=axissize)\n",
    "ax1.set_ylabel('Depth', fontsize=axissize)\n",
    "ax1.set_title(f'Max and Average weighted depth compared for {task_name}', fontsize=titlesize)\n",
    "ax1.legend(loc='upper left', fontsize=legendsize)\n",
    "ax1.grid(True)\n",
    "\n",
    "# Set tick sizes\n",
    "ax1.tick_params(axis='both', which='major', labelsize=ticksize)\n",
    "\n",
    "# Add 10% padding to y-axis limits\n",
    "y_min, y_max = ax1.get_ylim()\n",
    "ax1.set_ylim(0, y_max + 0.1 * (y_max - y_min))\n",
    "\n",
    "# Create a secondary y-axis for Average Weighted Depth\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(data['Number of Nodes'], data['Average Weighted Depth'], label='Average Weighted Depth', color='purple')\n",
    "\n",
    "# Set label for the secondary y-axis\n",
    "ax2.set_ylabel('Average Weighted Depth', fontsize=axissize, color='purple')\n",
    "ax2.tick_params(axis='y', labelcolor='purple', labelsize=ticksize)\n",
    "ax2.legend(loc='upper right', fontsize=legendsize)\n",
    "\n",
    "# Add 10% padding to secondary y-axis limits\n",
    "y2_min, y2_max = ax2.get_ylim()\n",
    "ax2.set_ylim(0, y2_max + 0.1 * (y2_max - y2_min))\n",
    "\n",
    "plt.savefig(f'plots/depth-awd-{task}.png', dpi=dpi)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axissize = 16\n",
    "legendsize = 12\n",
    "ticksize=13\n",
    "titlesize=14\n",
    "dpi=150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequential_access(df, title, opt_str):\n",
    "    # Rename columns\n",
    "    df.columns = ['Sequential accesses', 'Non-sequential accesses']\n",
    "\n",
    "    # Add an index for the number of samples\n",
    "    df.index = range(1, len(df) + 1)\n",
    "    df.index.name = 'Sample'\n",
    "\n",
    "    # Adjust the y-axis by multiplying by 100\n",
    "    df *= 100\n",
    "\n",
    "    # Create the area chart with the specified customizations\n",
    "    plt.figure(dpi=dpi)\n",
    "    df.plot(kind='area', stacked=True)\n",
    "    plt.title(title, fontsize=titlesize)\n",
    "    plt.xlabel('Iteration (thousands)', fontsize=axissize)\n",
    "    plt.ylabel('Percentage', fontsize=axissize)\n",
    "    plt.xticks(fontsize=ticksize)\n",
    "    plt.yticks(fontsize=ticksize)\n",
    "    plt.legend(title='Access Type', loc='center right', fontsize=legendsize, title_fontsize=legendsize)\n",
    "\n",
    "    plt.savefig(f'plots/seq-accesses-{opt_str}-{task}.png', dpi=dpi)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file\n",
    "df = pd.read_csv(fpath_opt_sorted_count)\n",
    "sequential_access(df, f\"Ratio of sequential accesses in a run with optimization for {task_name}\", \"opt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file\n",
    "df = pd.read_csv(fpath_notopt_sorted_count)\n",
    "sequential_access(df, f\"Ratio of sequential accesses in a run without optimization for {task_name}\", \"nonopt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
